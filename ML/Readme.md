# ğŸ·ï¸ Analyse Machine Learning du Dataset *Wine Quality*
### *Compte rendu complet avec pipeline Python*

---

## ğŸ“Œ 1. Contexte et objectif

Lâ€™objectif de ce travail est dâ€™analyser le dataset **Wine Quality** de lâ€™UCI Machine Learning Repository afin de :

- comprendre les relations entre les variables physico-chimiques des vins portugais,  
- explorer la distribution de la qualitÃ© du vin,  
- construire un modÃ¨le de Machine Learning capable de prÃ©dire cette qualitÃ©.

Le dataset contient des mesures pour des vins **rouges** et **blancs**, ainsi que leur note sensorielle.

---

## ğŸ“Š 2. Chargement et exploration de la base de donnÃ©es

Actions rÃ©alisÃ©es :

- Importation sous forme de DataFrame `pandas`
- VÃ©rification des dimensions et types des colonnes
- Recherche de valeurs manquantes (aucune dÃ©tectÃ©e)
- Visualisation des 5 premiÃ¨res lignes
- Ã‰tude de la variable cible `quality`

### ğŸ” Observations principales

- **4 898 lignes**
- **11 variables physico-chimiques**
- **Aucune valeur manquante**
- **Distribution dÃ©sÃ©quilibrÃ©e** des classes de qualitÃ©

---

## ğŸ” 3. PrÃ©traitement et visualisation

### âœ”ï¸ Analyse de corrÃ©lation
- Construction dâ€™une matrice de corrÃ©lation
- Heatmap pour visualiser les relations entre variables
- Identification des variables les plus corrÃ©lÃ©es avec la qualitÃ© (ex : taux dâ€™alcool)

### âœ”ï¸ PrÃ©paration des donnÃ©es
- SÃ©paration en **X** (features) et **y** (quality)
- Split **train / test** avec stratification
- Normalisation via `StandardScaler`

---

## ğŸ¤– 4. Pipeline Machine Learning utilisÃ©

### ğŸ“¦ Code Python du pipeline

```python
# Importation des bibliothÃ¨ques
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# Chargement du dataset
df = pd.read_csv("winequality-white.csv", sep=";")

# Variables explicatives et cible
X = df.drop("quality", axis=1)
y = df["quality"]

# DÃ©coupage en train/test avec stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Construction du pipeline
pipeline = Pipeline([
    ("scaler", StandardScaler()),                 # Normalisation
    ("knn", KNeighborsClassifier(n_neighbors=5))  # ModÃ¨le KNN
])

# EntraÃ®nement du modÃ¨le
pipeline.fit(X_train, y_train)

# PrÃ©dictions
y_pred = pipeline.predict(X_test)

# Ã‰valuation
acc = accuracy_score(y_test, y_pred)
print("Accuracy :", acc)
```
## ğŸ“‰ 5. RÃ©sultats obtenus

Les rÃ©sultats du modÃ¨le KNN appliquÃ© au dataset *Wine Quality* montrent que :

- Lâ€™accuracy obtenue se situe gÃ©nÃ©ralement entre **0.60 et 0.65**, selon la valeur du paramÃ¨tre *k*.  
- La normalisation via **StandardScaler** amÃ©liore significativement les performances du modÃ¨le.  
- La rÃ©partition dÃ©sÃ©quilibrÃ©e des classes affecte la prÃ©cision globale, notamment pour les notes les moins reprÃ©sentÃ©es.  
- Les faibles valeurs de *k* rendent le modÃ¨le plus sensible au bruit, tandis que les valeurs plus Ã©levÃ©es stabilisent les prÃ©dictions.  
- Les variables les plus influentes identifiÃ©es durant lâ€™analyse exploratoire incluent :  
  - le **taux dâ€™alcool**,  
  - lâ€™**aciditÃ© volatile**,  
  - la **densitÃ©**.

### ğŸ’¡ InterprÃ©tation

Les performances sont correctes pour un modÃ¨le simple comme KNN, mais la qualitÃ© rÃ©elle des prÃ©dictions reste limitÃ©e par :

- le **dÃ©sÃ©quilibre du dataset**,  
- la **nature multi-classes** de la variable cible,  
- la **forte proximitÃ©** entre certaines classes de qualitÃ© (notes 5, 6, 7).

---

## ğŸ“ 6. Conclusion gÃ©nÃ©rale

Cette Ã©tude sur le dataset *Wine Quality* a permis de :

- Explorer la structure et les caractÃ©ristiques physico-chimiques des vins portugais.  
- Mettre en place un pipeline complet incluant :  
  - la normalisation des donnÃ©es,  
  - le dÃ©coupage stratifiÃ© du dataset,  
  - lâ€™entraÃ®nement dâ€™un modÃ¨le KNN.  
- Ã‰valuer les performances du modÃ¨le et comprendre ses limites.

Les rÃ©sultats montrent que **KNN parvient Ã  fournir une prÃ©cision correcte**, mais quâ€™il reste limitÃ© par :

- la sensibilitÃ© Ã  lâ€™Ã©chelle des donnÃ©es,  
- le dÃ©sÃ©quilibre des classes,  
- la complexitÃ© de la tÃ¢che de classification multi-classes.

### ğŸ”® Perspectives dâ€™amÃ©lioration

Pour aller plus loin, plusieurs pistes peuvent Ãªtre envisagÃ©es :

- tester des modÃ¨les plus robustes (**Random Forest**, **SVM**, **Gradient Boosting**) ;  
- appliquer des techniques de rÃ©Ã©quilibrage des classes (**SMOTE**, oversampling, class weights) ;  
- optimiser davantage les hyperparamÃ¨tres ;  
- approfondir lâ€™analyse des relations entre variables via des mÃ©thodes avancÃ©es.

---

# ğŸ›’ E-commerce Fraud Detection  
ModÃ¨le de dÃ©tection de fraude appliquÃ© Ã  un dataset dâ€™e-commerce provenant de Kaggle.  
Lâ€™objectif est dâ€™identifier les transactions frauduleuses grÃ¢ce Ã  un pipeline complet de Machine Learning incluant prÃ©traitement, gestion du dÃ©sÃ©quilibre et modÃ©lisation.

---

## ğŸ“Œ 1. Description du projet

Les plateformes dâ€™e-commerce subissent de nombreuses tentatives de fraude.  
Ce projet vise Ã  :

- analyser un dataset rÃ©el de transactions,
- prÃ©parer et nettoyer les donnÃ©es,
- gÃ©rer le fort dÃ©sÃ©quilibre des classes,
- entraÃ®ner un modÃ¨le prÃ©dictif (Logistic Regression),
- Ã©valuer ses performances.

Ce travail permet de comprendre les facteurs influenÃ§ant la fraude et de construire un modÃ¨le operationnel pour les systÃ¨mes anti-fraude.

---

## ğŸ“¦ 2. Dataset utilisÃ©

Source :  
ğŸ‘‰ https://www.kaggle.com/datasets/umuttuygurr/e-commerce-fraud-detection-dataset

Le dataset contient des informations telles que :

- Ã¢ge du compte (`account_age_days`)
- distance dâ€™expÃ©dition (`shipping_distance_km`)
- frÃ©quence dâ€™achat du client (`total_transactions_user`)
- montant moyen (`avg_transaction_value`)
- type dâ€™appareil utilisÃ© (`device_os`)
- horodatage transformÃ© en sin/cos
- cible : **is_fraud**

Aucune valeur manquante n'Ã©tait prÃ©sente.

---

## âš™ï¸ 3. Pipeline Machine Learning utilisÃ©

```python
# Chargement du dataset
df = pd.read_csv('transactions.csv')

# SÃ©paration X / y
X = df.drop('is_fraud', axis=1)
y = df['is_fraud']

# Standardisation
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# SMOTE pour Ã©quilibrer les classes
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y)

# Split train-test
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42
)

# ModÃ©lisation
model = LogisticRegression(
    class_weight='balanced',
    max_iter=1000,
    random_state=42
)
model.fit(X_train, y_train)

# PrÃ©diction
y_pred = model.predict(X_test)

# Ã‰valuation
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
```
## ğŸ“Š 4. RÃ©sultats obtenus

Les mÃ©triques calculÃ©es incluaient :

- **Accuracy**
- **Precision**
- **Recall**
- **F1-score**
- **Confusion Matrix**

Ã‰tant donnÃ© lâ€™importance de dÃ©tecter les fraudes, la mÃ©trique clÃ© est :

### ğŸ¯ Recall de la classe 1 (fraude)
Le modÃ¨le obtient un **recall Ã©levÃ©**, ce qui signifie quâ€™il identifie la majoritÃ© des fraudes dans les donnÃ©es.  
Bien que cela engendre plus de faux positifs, ce compromis est acceptable dans un systÃ¨me anti-fraude.

### ğŸ” InterprÃ©tation globale

- Le modÃ¨le dÃ©tecte efficacement les transactions frauduleuses.  
- Lâ€™utilisation de **SMOTE** combinÃ©e Ã  `class_weight='balanced'` a amÃ©liorÃ© la reconnaissance de la classe minoritaire.  
- Le F1-score est stable et montre que le modÃ¨le Ã©quilibre correctement prÃ©cision et rappel.

---

## ğŸ§  5. Conclusion gÃ©nÃ©rale

Lâ€™analyse montre quâ€™un pipeline bien structurÃ© (standardisation + SMOTE + Logistic Regression) permet :

- dâ€™Ã©quilibrer correctement les classes,
- dâ€™amÃ©liorer fortement la dÃ©tection des fraudes,
- dâ€™obtenir un modÃ¨le performant et interprÃ©table,
- de comprendre les variables influenÃ§ant le comportement frauduleux.

### ğŸ”® AmÃ©liorations possibles

- Tester des modÃ¨les plus complexes (Random Forest, XGBoost, LightGBM)  
- Utiliser une recherche dâ€™hyperparamÃ¨tres (GridSearch / Optuna)  
- Ajouter une explicabilitÃ© avancÃ©e (SHAP, LIME)  
- Tester des seuils de dÃ©cision optimisÃ©s (ROC / PR curves)
- ## âœ¨ 7. Auteur

Projet rÃ©alisÃ© par **Mohammed Akhoussas**.
